#!/usr/bin/env python3
"""
create_experiment.py

This script uses LangGraph and gemini-2.5-flash-lite to generate optimization variable code
based on an experiment description, then inserts it into a copy of experiment_framework.py
and runs the modified experiment.
"""

import os
import re
import subprocess
from typing_extensions import Annotated, TypedDict

import google.generativeai as genai
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages


class ExperimentState(TypedDict):
    """
    State for the experiment generation workflow.
    
    This TypedDict defines the schema for the state object that flows through
    the LangGraph workflow. Each node in the workflow can read from and write to
    this state, allowing data to be passed between nodes.
    
    The 'messages' field uses LangGraph's add_messages annotation, which provides
    special handling for accumulating messages across workflow steps.
    
    Attributes:
        experiment_description: The user's natural language description of the 
                                experiment they want to run.
        experiment_id: Unique identifier for this experiment.
        output_file_path: Path where the final results will be saved.
        generated_code: Python code generated by Gemini for optimization variables.
        generated_constraints_code: Python code generated by Gemini for constraints
                                    and objective functions.
        modified_framework_path: File path to the modified experiment_framework.py
                                 with generated code inserted.
        experiment_error: Error message if the experiment execution failed.
        messages: List of message dictionaries with 'role' and 'content' keys,
                  used for logging and displaying workflow progress.
    """
    experiment_description: str
    experiment_id: str
    output_file_path: str
    generated_code: str
    generated_constraints_code: str
    modified_framework_path: str
    experiment_error: str
    messages: Annotated[list, add_messages]

def add_system_message(content: str) -> dict:
    """
    Create a system message to add to state.
    
    Helper function that creates a properly formatted message dictionary
    for adding system-level status updates to the workflow state.
    
    Args:
        content: The message content to display.
        
    Returns:
        A dictionary with a 'messages' key containing a list with one
        system message dict.
    """
    # Print the message live
    print(f"\n[SYSTEM] {content}")
    return {'messages': [{'role': 'system', 'content': content}]}

def generate_all_code(state: ExperimentState) -> dict:
    """
    Generate both optimization variables and constraints code using Gemini models.
    
    This node makes two separate LLM calls:
    1. Gemini 2.5 Flash-Lite to generate optimization variable code (faster, cheaper)
    2. Gemini 2.5 Flash to generate constraints/objective code (more capable)
    
    The prompts are loaded from disk within this node to keep the state clean.
    
    Args:
        state: The current workflow state containing:
               - experiment_description: User's experiment description
        
    Returns:
        A dictionary to update the state with:
        - generated_code: The optimization variables code from Gemini
        - generated_constraints_code: The constraints/objective code from Gemini
        - messages: Status messages for each generation step
    """
    # Define code generation steps
    generation_steps = [
        {
            'name': 'optimization',
            'prompt_file': './prompts/choose_optimisation_variables.txt',
            'model_name': 'gemini-2.5-flash-lite',
            'state_key': 'generated_code',
            'description': 'optimization code'
        },
        {
            'name': 'constraints',
            'prompt_file': './prompts/setup_constraints_and_objective.txt',
            'model_name': 'gemini-2.5-flash',
            'state_key': 'generated_constraints_code',
            'description': 'constraints code'
        }
    ]
    
    results = {
        'generated_code': '',
        'generated_constraints_code': '',
        'messages': []
    }
    
    # Generate code for each step
    for step in generation_steps:
        # Load prompt template
        try:
            with open(step['prompt_file'], 'r') as f:
                prompt_template = f.read()
        except FileNotFoundError as e:
            return {
                'generated_code': '',
                'generated_constraints_code': '',
                **add_system_message(f'Error: Could not find prompt file - {str(e)}')
            }
        
        # Generate code with Gemini
        try:
            model = genai.GenerativeModel(step['model_name'])
            
            full_prompt = f"""
{prompt_template}

EXPERIMENT DESCRIPTION: {state['experiment_description']}

"""
            
            response = model.generate_content(full_prompt)
            generated_code = response.text.strip()

            # If wrapped in ```python ... ```, extract the code block
            code_block_match = re.search(r'```python(.*?)```', generated_code, re.DOTALL)
            if code_block_match:
                generated_code = code_block_match.group(1).strip()
            
            # Store result
            results[step['state_key']] = generated_code
            results['messages'].append({
                'role': 'assistant',
                'content': f'Generated {step["description"]}:\n{generated_code}'
            })
            
            print(f"\n[ASSISTANT] Generated {step['description']}:\n{'-' * 60}\n{generated_code}\n{'-' * 60}")
            
        except Exception as e:
            # If first step fails, return empty results
            # If second step fails, keep first step's result
            return {
                **results,
                **add_system_message(f'Error generating {step["description"]} with Gemini: {str(e)}')
            }
    
    return results

def create_modified_framework(state: ExperimentState) -> dict:
    """
    Create a modified copy of experiment_framework.py with generated code inserted.
    
    This node takes the template framework file and uses regex replacement to insert
    the Gemini-generated code at two specific insertion points. The framework file
    contains sentinel comments that mark where the generated code should be inserted.
    
    Args:
        state: The current workflow state containing:
               - generated_code: Optimization variable code from Gemini
               - generated_constraints_code: Constraints/objective code from Gemini
        
    Returns:
        A dictionary to update the state with:
        - modified_framework_path: Path to the newly created modified framework file
        - messages: A status message indicating success or failure
    """
    # Validate that optimization variable code was generated successfully
    if not state.get('generated_code'):
        return add_system_message('Error: No generated code to insert')
    
    # Validate that constraints/objective code was generated successfully
    if not state.get('generated_constraints_code'):
        return add_system_message('Error: No generated constraints code to insert')
    
    try:
        # Read the template framework that exposes explicit placeholders for Gemini output.
        # The framework contains two marked sections where generated code will be inserted.
        with open('experiment_framework.py', 'r') as f:
            framework_content = f.read()

        # Insert optimization variables code at first insertion point
        # The regex preserves the sentinel comments and replaces the text between them.
        # Pattern: capture the opening comment, the content to replace, and the closing comment
        pattern1 = r'(# --- FIRST GEMINI INSERTION POINT ---\n)(.*?)(# --- END GEMINI INSERTION POINT ---)'
        replacement1 = f'\\1\n{state["generated_code"]}\n\n\\3'
        # re.DOTALL allows . to match newlines, so we can match multi-line content
        modified_content = re.sub(pattern1, replacement1, framework_content, flags=re.DOTALL)
        
        # Insert constraints and objective code at second insertion point
        # This mirrors the first replacement but targets the second placeholder block.
        pattern2 = r'(# --- SECOND GEMINI INSERTION POINT ---\n)(.*?)(# --- END GEMINI INSERTION POINT ---)'
        replacement2 = f'\\1\n{state["generated_constraints_code"]}\n\n\\3'
        modified_content = re.sub(pattern2, replacement2, modified_content, flags=re.DOTALL)
        
        # Define the output filename for the modified framework
        modified_filename = 'modified_experiment_framework.py'
        # Persist the modified script so the subprocess step can execute it.
        with open(modified_filename, 'w') as f:
            f.write(modified_content)
        
        return {
            'modified_framework_path': modified_filename,
            **add_system_message(f'Created modified framework: {modified_filename}')
        }
    except Exception as e:
        return add_system_message(f'Error creating modified framework: {str(e)}')

def run_experiment(state: ExperimentState) -> dict:
    """
    Run the modified experiment framework as a subprocess with live output.
    
    This is the final node in the workflow. It executes the modified framework file
    that contains the generated optimization code, streaming output in real-time
    to provide live feedback to the user.
    
    Args:
        state: The current workflow state containing:
               - modified_framework_path: Path to the framework file to execute
        
    Returns:
        A dictionary to update the state with:
        - experiment_error: Full error message/traceback if the subprocess failed
        - messages: A message containing the experiment result status
    """
    # Validate that the modified framework file was created successfully
    if not state.get('modified_framework_path'):
        return add_system_message('Error: No modified framework to run')
    
    try:
        print("\n[SYSTEM] Running experiment...")
        print("=" * 60)
        
        # Launch the modified framework as a child process.
        # Use -u flag for unbuffered output to get real-time streaming
        # Pass experiment_id and output_file_path as command-line arguments
        process = subprocess.Popen(
            ['python', '-u', state['modified_framework_path'], 
             state.get('experiment_id', 'default'),
             state.get('output_file_path', './experiment-results/experiment.md')],
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,  # Merge stderr into stdout for combined live output
            text=True,
            bufsize=1,  # Line buffered
            cwd='.'
        )
        
        # Capture all output
        output_lines = []
        
        # Read and print output line by line as it's produced
        for line in iter(process.stdout.readline, ''):
            if line:
                print(line, end='', flush=True)
                output_lines.append(line)
        
        # Wait for process to complete
        process.stdout.close()
        return_code = process.wait()
        
        print("=" * 60)
        
        # Combine all output
        full_output = ''.join(output_lines)
        
        # Check the return code to determine if the experiment succeeded or failed
        if return_code == 0:
            return {
                'experiment_error': '',
                'messages': [
                    {'role': 'system', 'content': 'Experiment completed successfully!'},
                    {'role': 'assistant', 'content': f'Experiment Output:\n```\n{full_output}\n```'}
                ]
            }
        else:
            # Include both the exit code and the full output in the error message
            error_msg = f"Process exited with code {return_code}"
            if full_output:
                error_msg += f"\n\nOutput:\n{full_output}"
            
            return {
                'experiment_error': error_msg,
                'messages': [
                    {'role': 'system', 'content': f'Experiment failed with exit code {return_code}'},
                    {'role': 'assistant', 'content': f'Experiment Output:\n```\n{full_output}\n```'}
                ]
            }
    except Exception as e:
        error_msg = str(e)
        return {
            'experiment_error': error_msg,
            **add_system_message(f'Error running experiment: {error_msg}')
        }

def correct_code_error(state: ExperimentState) -> dict:
    """
    Handle errors from the experiment execution.
    
    This node is conditionally called when run_experiment fails. It prints the
    error details to help with debugging.
    
    Args:
        state: The current workflow state containing:
               - experiment_error: The error message from the failed experiment
        
    Returns:
        A dictionary to update the state with status messages
    """
    error = state.get('experiment_error', 'Unknown error')
    return add_system_message(f'Attempting to correct code error:\n{error}')

def clean_up(state: ExperimentState) -> dict:
    """
    Clean up temporary files and save the final workflow results to markdown.
    
    This node is the final step in the workflow. It saves the workflow messages
    to a markdown file and removes temporary files created during execution.
    
    Args:
        state: The current workflow state containing:
               - output_file_path: Path where results will be saved
               - experiment_id: Unique identifier for the experiment
               - experiment_description: Description of the experiment
               - experiment_error: Error message if execution failed
               - modified_framework_path: Path to temporary framework file
               - messages: All workflow messages
        
    Returns:
        A dictionary to update the state with cleanup status messages
    """
    # Save the workflow messages to a markdown file
    try:
        output_file_path = state.get('output_file_path', 'experiment_results.md')
        experiment_id = state.get('experiment_id', 'unknown')
        experiment_description = state.get('experiment_description', 'No description')
        generated_code = state.get('generated_code', '')
        generated_constraints_code = state.get('generated_constraints_code', '')
        experiment_error = state.get('experiment_error', '')
        
        # Extract experiment output from messages
        experiment_output = ''
        for msg in state.get('messages', []):
            if isinstance(msg, dict):
                content = msg.get('content', '')
            else:
                content = getattr(msg, 'content', str(msg))
            
            if 'Experiment Output:' in content:
                # Extract the output from the code block
                output_match = re.search(r'Experiment Output:\n```\n(.*?)\n```', content, re.DOTALL)
                if output_match:
                    experiment_output = output_match.group(1).strip()
                break
        
        # Construct plot file path
        output_dir = os.path.dirname(output_file_path)
        plot_filename = f"{experiment_id}_plot.png"
        plot_path = os.path.join(output_dir, plot_filename)
        
        # Construct workflow diagram file path
        workflow_filename = f"{experiment_id}_workflow.png"
        workflow_path = os.path.join(output_dir, workflow_filename)
        
        with open(output_file_path, 'w') as f:
            f.write(f"# Experiment Results\n\n")
            f.write(f"**Experiment ID:** `{experiment_id}`\n\n")
            f.write(f"**Description:** {experiment_description}\n\n")
            f.write(f"**Status:** {'✅ SUCCESS' if not experiment_error else '❌ FAILED'}\n\n")
            
            # Workflow diagram
            if os.path.exists(workflow_path):
                f.write("## Workflow\n\n")
                f.write(f"![Workflow Diagram]({workflow_filename})\n\n")
            
            # Optimization code
            if generated_code:
                f.write("## Optimization Variables\n\n")
                f.write("```python\n")
                f.write(generated_code)
                f.write("\n```\n\n")
            
            # Constraints and objective code
            if generated_constraints_code:
                f.write("## Constraints and Objective\n\n")
                f.write("```python\n")
                f.write(generated_constraints_code)
                f.write("\n```\n\n")
            
            # Experiment output
            if experiment_output:
                f.write("## Experiment Output\n\n")
                f.write("```\n")
                f.write(experiment_output)
                f.write("\n```\n\n")
            
            # Error information
            if experiment_error:
                f.write("## Error\n\n")
                f.write("```\n")
                f.write(experiment_error)
                f.write("\n```\n\n")
            
            # Link to plot
            if os.path.exists(plot_path):
                f.write("## Visualization\n\n")
                f.write(f"![Wing Plot]({plot_filename})\n\n")
        
        print(f"\n[SYSTEM] Experiment results saved to: {output_file_path}")
        
    except Exception as e:
        print(f"\n[SYSTEM] Error saving results to file: {str(e)}")
    
    # Clean up temporary files
    try:
        modified_framework_path = state.get('modified_framework_path')
        if modified_framework_path and os.path.exists(modified_framework_path):
            os.remove(modified_framework_path)
            print(f"[SYSTEM] Cleaned up temporary file: {modified_framework_path}")
    except Exception as e:
        print(f"[SYSTEM] Error cleaning up temporary files: {str(e)}")
    
    return add_system_message('Workflow cleanup completed')

def should_correct_error(state: ExperimentState) -> str:
    """
    Conditional routing function to determine if error correction is needed.
    
    This function is used by LangGraph to decide whether to route to the
    correct_code_error node or proceed directly to cleanup.
    
    Args:
        state: The current workflow state containing:
               - experiment_error: Error message (empty string if no error)
        
    Returns:
        "correct_error" if there was an error, "clean_up" otherwise
    """
    if state.get('experiment_error'):
        return "correct_error"
    return "clean_up"

def create_experiment_workflow(experiment_id: str, output_dir: str) -> StateGraph:
    """
    Create the LangGraph workflow for experiment generation.
    
    This function constructs a state machine using LangGraph that orchestrates the entire
    experiment generation process. The workflow consists of nodes that execute in sequence,
    with conditional routing based on experiment success/failure:
    
    1. generate_all_code: Use Gemini models to generate both optimization variables and constraints
    2. create_framework: Insert generated code into experiment_framework.py
    3. run_experiment: Execute the modified framework as a subprocess
    4. correct_code_error: (Conditional) Handle errors if experiment fails
    5. clean_up: Save results and clean up temporary files
    
    Args:
        experiment_id: Unique identifier for the experiment
        output_dir: Directory where the workflow diagram will be saved
    
    Returns:
        A compiled LangGraph workflow ready to be invoked with an initial state
    """
    # Build a LangGraph state machine where each node encapsulates one stage of the automation.
    # StateGraph manages the flow of the ExperimentState dictionary between nodes.
    workflow = StateGraph(ExperimentState)
    
    # Register the individual steps as nodes in the graph.
    # Each node is a function that receives the current state and returns updates to merge.
    workflow.add_node("generate_all_code", generate_all_code)
    workflow.add_node("create_framework", create_modified_framework)
    workflow.add_node("run_experiment", run_experiment)
    workflow.add_node("correct_error", correct_code_error)
    workflow.add_node("clean_up", clean_up)
    
    # Wire the nodes in execution order with conditional routing after run_experiment.
    # Each edge defines the transition from one node to the next.
    workflow.set_entry_point("generate_all_code")  # Start here when workflow is invoked
    workflow.add_edge("generate_all_code", "create_framework")
    workflow.add_edge("create_framework", "run_experiment")
    
    # Add conditional routing after run_experiment
    workflow.add_conditional_edges(
        "run_experiment",
        should_correct_error,  # Function that returns "correct_error" or "clean_up"
        {
            "correct_error": "correct_error",
            "clean_up": "clean_up"
        }
    )
    
    # After correcting error or success, go to clean_up
    workflow.add_edge("correct_error", "clean_up")
    workflow.add_edge("clean_up", END)
    
    # Compile the workflow into an executable graph
    compiled_workflow = workflow.compile()
    
    # Generate and save the workflow diagram as PNG
    try:
        from PIL import Image
        import io
        
        # Get Mermaid diagram from the compiled workflow
        mermaid_png = compiled_workflow.get_graph().draw_mermaid_png()
        
        # Save the PNG
        workflow_filename = f"{experiment_id}_workflow.png"
        workflow_path = os.path.join(output_dir, workflow_filename)
        
        with open(workflow_path, 'wb') as f:
            f.write(mermaid_png)
        
        print(f"[SYSTEM] Workflow diagram saved to: {workflow_path}")
    except Exception as e:
        print(f"[SYSTEM] Warning: Could not generate workflow diagram: {str(e)}")
    
    return compiled_workflow

def execute_experiment(
    experiment_description: str,
    experiment_id: str,
    output_file_path: str
) -> dict:
    """
    Execute the full experiment generation workflow and save results to a file.
    
    This function orchestrates the complete experiment generation process:
    1. Creates and runs the LangGraph workflow
    2. Generates optimization and constraint code using Gemini
    3. Creates and executes the modified experiment framework
    4. Saves the workflow messages to a markdown file
    
    Args:
        experiment_description: Natural language description of the experiment
        experiment_id: Unique identifier for this experiment
        output_file_path: Path where the final results will be saved
        
    Returns:
        The final state dictionary from the workflow execution
    """
    # Initialize state with the experiment description and metadata
    initial_state = ExperimentState(
        experiment_description=experiment_description,
        experiment_id=experiment_id,
        output_file_path=output_file_path,
        generated_code="",
        generated_constraints_code="",
        modified_framework_path="",
        experiment_error="",
        messages=[]
    )
    
    # Create and run the workflow
    print("\n")
    print("=" * 60)
    print("⚙️  Running Experiment Generation Workflow")
    print(f"Experiment ID: {experiment_id}")
    print("=" * 60)
    
    output_dir = os.path.dirname(output_file_path)
    workflow = create_experiment_workflow(experiment_id, output_dir)
    final_state = workflow.invoke(initial_state)
    
    return final_state

def main() -> None:
    """
    Main function to run the experiment creation workflow.
    
    This is the entry point for the script. It performs the following steps:
    1. Validates that the GEMINI_API_KEY environment variable is set
    2. Configures the Gemini API with the provided key
    3. Prompts the user for an experiment description
    4. Initializes the workflow state with the user's input
    5. Executes the LangGraph workflow to generate and run the experiment
    6. Messages are printed live as the workflow progresses
    """
    # Configure Gemini API
    # The workflow relies on Gemini so we fail fast if the credential is missing.
    api_key = os.getenv('GEMINI_API_KEY')
    if not api_key:
        print("Error: Please set your GEMINI_API_KEY environment variable")
        print("You can get an API key from: https://ai.google.dev/")
        return
    
    # Configure the Gemini API client with the retrieved API key
    genai.configure(api_key=api_key)
    
    # Get experiment description from user
    # Collect a free-form description that will be threaded into both prompts.
    print("\n")
    print("=" * 60)
    print("🚀 AeroSandBox Experiment Generator")
    print("=" * 60)
    print("\nThis tool will generate optimization variables based on your experiment description.\n")
    print("Example: 'Optimise the chord lengths and angle of attack (within 0 and 30 degrees)")
    print("to minimise the drag coefficient, with a required lift coefficient of 1,")
    print("a fixed wing area of 0.25 and monotonically decreasing chord lengths from root to tip.'\n")
    
    # Prompt the user for their experiment description
    experiment_description = input("Enter your experiment description: ").strip()
    if not experiment_description:
        print("Error: Please provide an experiment description")
        return
    
    # Generate experiment ID and output file path
    from datetime import datetime
    experiment_id = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file_path = f"./experiment-results/{experiment_id}.md"
    
    # Execute the experiment workflow and save results
    execute_experiment(
        experiment_description=experiment_description,
        experiment_id=experiment_id,
        output_file_path=output_file_path
    )


if __name__ == "__main__":
    main()
